package org.deeplearning4j.optimize.solvers.accumulation;

import lombok.NonNull;
import org.nd4j.linalg.api.memory.MemoryWorkspace;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.factory.Nd4j;

import java.io.Serializable;
import java.util.ArrayList;
import java.util.List;
import java.util.Queue;
import java.util.concurrent.CopyOnWriteArrayList;
import java.util.concurrent.CyclicBarrier;
import java.util.concurrent.LinkedTransferQueue;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;

/**
 * This class provides accumulation for gradients for both input (i.e. updates coming from network) and output (comint from one ore more models training at the same time)
 *
 * @author raver119@gmail.com
 */
public class GradientsAccumulator implements Serializable {

    protected MessageHandler handler;

    // here we'll store messages coming from "somewhere else"
    protected transient Queue<INDArray> gradients;

    // this field stores current accumulated
    protected transient INDArray storage;

    // this counter tracks number of messages generated by this accumulation
    protected transient AtomicLong ownCounter = new AtomicLong(0);

    // this counter tracks number of messages received from somewhere
    protected transient AtomicLong extCounter = new AtomicLong(0);

    // FIXME: this mechanics should be improved i think.
    protected int[] shape;
    protected char ordering;

    protected List<INDArray> consumerData = new ArrayList<>();
    protected List<Object> consumerLocks = new ArrayList<>();
    protected ThreadLocal<Integer> consumerIndex = new ThreadLocal<>();
    protected AtomicInteger consumers = new AtomicInteger(0);


    protected int parties = 0;
    protected CyclicBarrier barrier;
    protected AtomicLong firstOne = new AtomicLong(0);
    protected List<INDArray> candidates = new CopyOnWriteArrayList<>();

    /**
     * Creates new GradientsAccumulator with starting threshold of 1e-3
     */
    public GradientsAccumulator(int parties) {
        this(parties, new LocalHandler());
    }

    /**
     * Creates new GradientsAccumulator with custom starting threshold
     *
     * @param handler MessageHandler instance that'll be used for communication purposes
     */
    public GradientsAccumulator(int parties, @NonNull MessageHandler handler) {
        this.gradients = new LinkedTransferQueue<>();
        this.handler = handler;

        this.handler.initialize(this);
        this.parties = parties;
        barrier = new CyclicBarrier(parties);
    }

    // FIXME: this implementation is wrong, and might cause rc
    public INDArray getUpdate() {
        synchronized (this) {
            if (consumerIndex.get() == null) {
                try (MemoryWorkspace workspace = Nd4j.getMemoryManager().scopeOutOfWorkspaces()) {
                    consumerData.add(Nd4j.create(shape, ordering));
                    consumerLocks.add(new Object());
                    consumerIndex.set(consumers.getAndIncrement());
                }
            }
        }

        synchronized (consumerLocks.get(consumerIndex.get())) {
            // this code should run within workspace

            INDArray updates = consumerData.get(consumerIndex.get());
            INDArray ret = updates.dup(ordering);

            Nd4j.getExecutioner().commit();

            // we assign to 0.0, so all future incoming updates will be able to call for addi here
            updates.assign(0.0);

            return ret;
        }
    }

    /**
     * This method accepts updates suitable for StepFunction, and accumulates/propagates it across all workers
     *
     * @param array
     */
    // TODO: this method should be synchronized probably, if we want to call this method from different threads
    public void storeUpdate(INDArray array) {
        /*
            Here we want to do 4 things:
            1) update accumulated values
            2) invoke extractor, that'll (optionally) pull all updates above threshold
            3) ???
            4) PROFIT!
         */

        try {
            firstOne.compareAndSet(0, Thread.currentThread().getId());

            // TODO: since we know number of elements in advance, we don't really need CopyOnWrite list here.
            candidates.add(array);
            barrier.await();

            if (firstOne.get() == Thread.currentThread().getId()) {
                // if accum is null, let's just create it here
                if (storage == null) {
                    // we don't want state array to be attached to any workspace
                    shape = array.shape();
                    ordering = array.ordering();

                    try (MemoryWorkspace workspace = Nd4j.getMemoryManager().scopeOutOfWorkspaces()) {
                        // TODO: if p2p isn't supported, this should become HOST-only allocation
                        storage = Nd4j.create(shape, ordering);
                    }
                }

                // accumulate our values, a
                //storage.addi(array);
                Nd4j.accumulate(storage, candidates);

                // we ensure storage was updated successfully
                Nd4j.getExecutioner().commit();

                // if there's something to send - send it. Skip otherwise!!!
                if (handler.broadcastUpdates(storage)) {
                    ownCounter.getAndIncrement();
                }

                // reset "first one" :)
                firstOne.set(0);
                candidates.clear();
            }

            barrier.await();

        } catch (Exception e) {
            // do something here
        }
    }


    /**
     * This method accepts updates suitable for StepFunction and puts them to the queue, which is used in backpropagation loop
     *
     * @param array
     */
    public void receiveUpdate(INDArray array) {
        extCounter.getAndIncrement();

        // FIXME: something better needed here
        for (int i = 0; i < consumerData.size(); i++) {
            synchronized (consumerLocks.get(i)) {
                consumerData.get(i).addi(array);
            }
        }

        // we have to ensure, all operations were finished here
        Nd4j.getExecutioner().commit();
    }


    /**
     * This method resets all accumulated updates (if any)
     */
    public void reset() {
        if (storage != null)
            storage.assign(0.0f);
    }
}
